{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Foundation: Class 6 topics\n",
    "    Data Manipulation / Data Cleaning\n",
    "    - Structural\n",
    "    - Content based\n",
    "> <div> 1. Filters <br/>\n",
    "        2. Sort <br/>\n",
    "        3. Removal of duplicates <br/>\n",
    "        4. Data imputation <br/>\n",
    "            - Missing value treatment <br/>\n",
    "            - Outlier treatment <br/>\n",
    "        5. Binning or Grouping of the data <br/>\n",
    "        6. Encoding <br/>\n",
    "        7. Grouping of the data / Summaries <br/>\n",
    "        8. Joins / Merge <br/>\n",
    "        9. Appending <br/>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removal of duplicates\n",
    "score = pd.read_csv(\"D:/SampleData/Score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate records from score dataset << drop_duplicates() >>\n",
    "\n",
    "# remove the duplicate records from score dataset basis Student column << duplicated() >>\n",
    "\n",
    "# remove the duplicate records from score dataset basis Student and Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate records from score dataset << drop_duplicates() >>\n",
    "score.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate records from score dataset basis Student column << duplicated() >>\n",
    "score[score.Student.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate records from score dataset basis Student and Section\n",
    "score[score[['Student', 'Section']].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputaion - Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imputation: Missing values << AcqCostPercust >>\n",
    "stores = pd.read_csv('D:/SampleData/stores.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the %age of missing values from the data\n",
    "1 - stores.count()/stores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detect missing values << isna() / isnull() / notnull() >>\n",
    "\n",
    "# 2. With a zero or an empty string << fillna() >>\n",
    "\n",
    "# 3. With the mean or median << fillna() >>\n",
    "\n",
    "# 4. Remove the rows where there are missing << dropna() >>\n",
    "\n",
    "# 5. Drop the column if its not so important and has lots of missings << dropna() >>\n",
    "\n",
    "# 6. Use any predictive mod tech to guess the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detect missing values << isna() / isnull() / notnull() >>\n",
    "stores.AcqCostPercust.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. With a zero or an empty string << fillna() >>\n",
    "stores.AcqCostPercust.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. With the mean or median << fillna() >>\n",
    "stores.AcqCostPercust.fillna(stores.AcqCostPercust.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove the rows where there are missing << dropna() >>\n",
    "stores.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Drop the column if its not so important and has lots of missings << dropna() >>\n",
    "stores.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputaion - Outliers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data imputation: Outlier Treatment << TotalSales >>\n",
    "# Values which are the odds from the complete population\n",
    "    \n",
    "    .clip_lower()\n",
    "    .clip_upper()\n",
    "    .clip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip the values with lower limit at 100 and upper at 400\n",
    "stores.TotalSales.clip(lower = 100, upper = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip the values at 5 and 95 percentiles from TotalSales\n",
    "stores.TotalSales.clip(lower = stores.TotalSales.quantile(.05), upper = stores.TotalSales.quantile(.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins and Groups"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Binning: pd.cut()\n",
    "    1. Automatic binning pd.cut(pd.Series, int, labels=[])\n",
    "    2. Manual binning using user defined ranges pd.cut(pd.Series, range(min, max + 1, step), labels=[])\n",
    "    \n",
    "# Grouping\n",
    "    1. Using user defined ranges pd.cut(pd.Series, [ordered list], labels=[])\n",
    "    2. numpy.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins\n",
    "# stores.TotalSales\n",
    "stores['Bins'] = pd.cut(stores.TotalSales, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(stores.TotalSales, range(50, 1000, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(stores.TotalSales, [0, 100, 400, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores[['TotalSales', 'Bins']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.where - alternate of if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (conditions, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(x > 10, \"Positive\", \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores[\"Region\"] = np.where((stores.Location == \"Delhi\"), \"North\",\n",
    "            np.where((stores.Location == \"Chennai\"), \"South\",\n",
    "                     np.where((stores.Location == \"Kolkata\"), \"East\",\n",
    "                              np.where((stores.Location == \"Mumbai\"), \"West\", \"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and aggregate data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GROUP BY: two step process << df.groupby >>\n",
    "    1. use groupby\n",
    "    2. use agg functions or agg or apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total sales for each location\n",
    "\n",
    "# get total and average Sales for each location\n",
    "\n",
    "# get the total sales and total operating cost for each Location\n",
    "\n",
    "# get the total and average sales and operating cost for each Location\n",
    "\n",
    "# get the total sales and average operating cost for each Location\n",
    "\n",
    "# get total sales for each Location and Store Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total sales for each location\n",
    "stores.groupby('Location').TotalSales.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total and average Sales for each location\n",
    "stores.groupby('Location').TotalSales.agg(['sum', 'mean']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total and average Sales for each location - Change column names\n",
    "stores.groupby('Location').TotalSales.agg({'Total of TotalSales': 'sum', 'Average of TotalSales': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total sales and total operating cost for each Location\n",
    "temp = stores.groupby('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['TotalSales', 'OperatingCost'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.groupby('Location')['TotalSales', 'OperatingCost'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total and average sales and operating cost for each Location\n",
    "stores.groupby('Location')['TotalSales', 'OperatingCost'].agg(['sum', 'mean']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total sales and average operating cost for each Location\n",
    "stores.groupby('Location')['TotalSales', 'OperatingCost'].agg({'TotalSales': 'sum', 'OperatingCost': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total sales for each Location and Store Type\n",
    "stores.groupby(['StoreType', 'Location']).TotalSales.sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins/Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins/merge << pd.merge() >>\n",
    "demographic = pd.read_csv('D:/SampleData/Demographic_Data.csv')\n",
    "transaction = pd.read_csv('D:/SampleData/Transaction_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "pd.merge(left = demographic, right= transaction, left_on = 'CustName', right_on='CustomerName', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join \n",
    "pd.merge(left = demographic, right= transaction, left_on = 'CustName', right_on='CustomerName', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join \n",
    "pd.merge(left = demographic, right= transaction, left_on = 'CustName', right_on='CustomerName', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join \n",
    "pd.merge(left = demographic, right= transaction, left_on = 'CustName', right_on='CustomerName', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions on Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details of registered patients and date of their visits?\n",
    "# Get the list of patients who have not yet registered with us?\n",
    "# Get the list of registered patients who have never make a visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datasets\n",
    "demog = pd.read_excel('D:/SampleData/Demog.xlsx', sheets = 'Demog')\n",
    "visit = pd.read_excel('D:/SampleData/Visits.xlsx', sheets = 'Visits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details of all registered patients and date of their visits?\n",
    "pd.merge(left = demog, right = visit, left_on= 'P_ID', right_on = 'PATIENT_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of patients who have not yet registered with us?\n",
    "df = pd.merge(left = demog, right = visit, left_on= 'P_ID', right_on = 'PATIENT_ID', how = 'right')\n",
    "df.loc[df.P_ID.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of registered patients who have never make a visit?\n",
    "df = pd.merge(left = demog, right = visit, left_on= 'P_ID', right_on = 'PATIENT_ID', how = 'left')\n",
    "df.loc[df.PATIENT_ID.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the data << df1.append(df2) >>\n",
    "Q1 = pd.read_csv('D:/SampleData/POS_Q1.csv')\n",
    "Q2 = pd.read_csv('D:/SampleData/POS_Q2.csv')\n",
    "Q3 = pd.read_csv('D:/SampleData/POS_Q3.csv')\n",
    "Q4 = pd.read_csv('D:/SampleData/POS_Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.append([Q2, Q3, Q4], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.append(Q2).reset_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
